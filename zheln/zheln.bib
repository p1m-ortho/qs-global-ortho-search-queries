% Encoding: UTF-8

@Article{Rada2013486490,
  author          = {Rada, Gabriel and Pérez, Daniel and Capurro, Daniel},
  journal         = {Studies in health technology and informatics},
  title           = {Epistemonikos: a free, relational, collaborative, multilingual database of health evidence.},
  year            = {2013},
  issn            = {1879-8365},
  pages           = {486--490},
  volume          = {192},
  abstract        = {Epistemonikos (www.epistemonikos.org) is a free, multilingual database of the best available health evidence. This paper describes the design, development and implementation of the Epistemonikos project. Using several web technologies to store systematic reviews, their included articles, overviews of reviews and structured summaries, Epistemonikos is able to provide a simple and powerful search tool to access health evidence for sound decision making. Currently, Epistemonikos stores more than 115,000 unique documents and more than 100,000 relationships between documents. In addition, since its database is translated into 9 different languages, Epistemonikos ensures that non-English speaking decision-makers can access the best available evidence without language barriers.},
  citation-subset = {T},
  completed       = {2015-04-06},
  country         = {Netherlands},
  issn-linking    = {0926-9630},
  keywords        = {Artificial Intelligence; Cooperative Behavior; Database Management Systems; Databases, Factual; Health Services Research; Information Storage and Retrieval, methods; Internet; Language; Multilingualism; Natural Language Processing; Periodicals as Topic; Software},
  nlm-id          = {9214582},
  owner           = {NLM},
  pmid            = {23920602},
  pubmodel        = {Print},
  pubstate        = {ppublish},
  revised         = {2013-08-07},
}

@Article{Izcovich2017e16113,
  author          = {Izcovich, Ariel and Criniti, Juan Martín and Popoff, Federico and Ragusa, Martín Alberto and Gigler, Cristel and Gonzalez Malla, Carlos and Clavijo, Manuela and Manzotti, Matias and Diaz, Martín and Catalano, Hugo Norberto and Neumann, Ignacio and Guyatt, Gordon},
  journal         = {BMJ open},
  title           = {Answering medical questions at the point of care: a cross-sectional study comparing rapid decisions based on PubMed and Epistemonikos searches with evidence-based recommendations developed with the GRADE approach.},
  year            = {2017},
  issn            = {2044-6055},
  month           = aug,
  pages           = {e016113},
  volume          = {7},
  abstract        = {Using the best current evidence to inform clinical decisions remains a challenge for clinicians. Given the scarcity of trustworthy clinical practice guidelines providing recommendations to answer clinicians' daily questions, clinical decision support systems (ie, assistance in question identification and answering) emerge as an attractive alternative. The trustworthiness of the recommendations achieved by such systems is unknown. To evaluate the trustworthiness of a question identification and answering system that delivers timely recommendations. Cross-sectional study. We compared the responses to 100 clinical questions related to inpatient management provided by two rapid response methods with 'Gold Standard' recommendations. One of the rapid methods was based on PubMed and the other on Epistemonikos database. We defined our 'Gold Standard' as trustworthy published evidence-based recommendations or, when unavailable, recommendations developed locally by a panel of six clinicians following the Grading of Recommendations Assessment, Development and Evaluation (GRADE) approach. Recommendations provided by the rapid strategies were classified as potentially misleading or reasonable. We also determined if the potentially misleading recommendations could have been avoided with the appropriate implementation of searching and evidence summary tools. We were able to answer all of the 100 questions with both rapid methods. Of the 200 recommendations obtained, 6.5% (95% CI 3% to 9.9%) were classified as potentially misleading and 93.5% (95% CI 90% to 96.9%) as reasonable. 6 of the 13 potentially misleading recommendations could have been avoided by the appropriate usage of the Epistemonikos matrix tool or by constructing summary of findings tables. No significant differences were observed between the evaluated rapid response methods. A question answering service based on the GRADE approach proved feasible to implement and provided appropriate guidance for most identified questions. Our approach could help stakeholders in charge of managing resources and defining policies for patient care to improve evidence-based decision-making in an efficient and feasible manner.},
  citation-subset = {IM},
  completed       = {2018-01-24},
  country         = {England},
  doi             = {10.1136/bmjopen-2017-016113},
  issn-linking    = {2044-6055},
  issue           = {8},
  keywords        = {Clinical Decision-Making, methods; Cross-Sectional Studies; Decision Support Systems, Clinical, standards; Evidence-Based Medicine, standards; Humans; Information Storage and Retrieval, standards; Point-of-Care Systems; Practice Guidelines as Topic; PubMed, standards; Qualitative Research; decision support; evidence based practice; informationist},
  nlm-id          = {101552874},
  owner           = {NLM},
  pii             = {bmjopen-2017-016113},
  pmc             = {PMC5629721},
  pmid            = {28790039},
  pubmodel        = {Electronic},
  pubstate        = {epublish},
  revised         = {2019-02-02},
}

@Article{NoelStorr2020S0895435620311100,
  author          = {Noel-Storr, Anna and Dooley, Gordon and Affengruber, Lisa and Gartlehner, Gerald},
  journal         = {Journal of clinical epidemiology},
  title           = {Citation screening using crowdsourcing and machine learning produced accurate results: evaluation of Cochrane's modified Screen4Me service.},
  year            = {2020},
  issn            = {1878-5921},
  month           = sep,
  abstract        = {To assess the feasibility of a modified workflow that uses machine learning and crowdsourcing to identify studies for potential inclusion in a systematic review. This was a sub-study to a larger randomised study; the main study sought to assess the performance of single screening search results versus dual screening. This sub-study assessed the performance in identifying relevant RCTs for a published Cochrane review of a modified version of Cochrane's Screen4Me workflow which uses crowdsourcing and machine learning. We included participants who had signed up for the main study but who were not eligible to be randomised to the two main arms of that study. The records were put through the modified workflow where a machine learning classifier divided the dataset into "Not RCTs" and "Possible RCTs". The records deemed "Possible RCTs" were then loaded into a task created on the Cochrane Crowd platform and participants classified those records as either "Potentially relevant" or "Not relevant" to the review. Using a pre-specified agreement algorithm we calculated the performance of the crowd in correctly identifying the studies that were included in the review (sensitivity) and correctly rejecting those that were not included (specificity). The RCT machine learning classifier did not reject any of the included studies. In terms of the crowd, 112 participants were included in this sub-study. Of these, 81 completed the training module and went on to screen records in the live task. Applying the Cochrane Crowd agreement algorithm, the crowd achieved 100% sensitivity and 80.71% specificity. Using a crowd to screen search results for systematic reviews can be an accurate method as long as the agreement algorithm in place is robust. Open Science Framework: https://osf.io/3jyqt.},
  citation-subset = {IM},
  country         = {United States},
  doi             = {10.1016/j.jclinepi.2020.09.024},
  issn-linking    = {0895-4356},
  keywords        = {accuracy; agreement algorithm; crowdsourcing; human computation; literature screening; machine learning; systematic reviews},
  nlm-id          = {8801383},
  owner           = {NLM},
  pii             = {S0895-4356(20)31110-0},
  pmid            = {33007457},
  pubmodel        = {Print-Electronic},
  pubstate        = {aheadofprint},
  revised         = {2020-10-02},
}

@Article{Marshall2020ocaa163,
  author          = {Marshall, Iain J. and Nye, Benjamin and Kuiper, Joël and Noel-Storr, Anna and Marshall, Rachel and Maclean, Rory and Soboczenski, Frank and Nenkova, Ani and Thomas, James and Wallace, Byron C.},
  journal         = {Journal of the American Medical Informatics Association : JAMIA},
  title           = {Trialstreamer: A living, automatically updated database of clinical trial reports.},
  year            = {2020},
  issn            = {1527-974X},
  month           = sep,
  abstract        = {Randomized controlled trials (RCTs) are the gold standard method for evaluating whether a treatment works in health care but can be difficult to find and make use of. We describe the development and evaluation of a system to automatically find and categorize all new RCT reports. Trialstreamer continuously monitors PubMed and the World Health Organization International Clinical Trials Registry Platform, looking for new RCTs in humans using a validated classifier. We combine machine learning and rule-based methods to extract information from the RCT abstracts, including free-text descriptions of trial PICO (populations, interventions/comparators, and outcomes) elements and map these snippets to normalized MeSH (Medical Subject Headings) vocabulary terms. We additionally identify sample sizes, predict the risk of bias, and extract text conveying key findings. We store all extracted data in a database, which we make freely available for download, and via a search portal, which allows users to enter structured clinical queries. Results are ranked automatically to prioritize larger and higher-quality studies. As of early June 2020, we have indexed 673 191 publications of RCTs, of which 22 363 were published in the first 5 months of 2020 (142 per day). We additionally include 304 111 trial registrations from the International Clinical Trials Registry Platform. The median trial sample size was 66. We present an automated system for finding and categorizing RCTs. This yields a novel resource: a database of structured information automatically extracted for all published RCTs in humans. We make daily updates of this database available on our website (https://trialstreamer.robotreviewer.net).},
  citation-subset = {IM},
  country         = {England},
  doi             = {10.1093/jamia/ocaa163},
  issn-linking    = {1067-5027},
  keywords        = {automatic database curation; evidence based medicine; randomized controlled trials; research synthesis},
  nlm-id          = {9430800},
  owner           = {NLM},
  pii             = {ocaa163},
  pmid            = {32940710},
  pubmodel        = {Print-Electronic},
  pubstate        = {aheadofprint},
  revised         = {2020-09-17},
}

@Comment{jabref-meta: databaseType:bibtex;}

@article{NoelStorr2020S0895435620301165,
	title = {Cochrane {Centralised} {Search} {Service} showed high sensitivity identifying randomized controlled trials: {A} retrospective analysis},
	issn = {1878-5921},
	shorttitle = {Cochrane {Centralised} {Search} {Service} showed high sensitivity identifying randomized controlled trials},
	doi = {10.1016/j.jclinepi.2020.08.008},
	abstract = {BACKGROUND AND OBJECTIVES: The Cochrane Central Register of Controlled Trials (CENTRAL) is compiled from a number of sources, including PubMed and Embase. Since 2017, we have increased the number of sources feeding into CENTRAL and improved the efficiency of our processes through the use of application programming interfaces, machine learning, and crowdsourcing.Our objectives were twofold: (1) Assess the effectiveness of Cochrane's centralized search and screening processes to correctly identify references to published reports which are eligible for inclusion in Cochrane systematic reviews of randomized controlled trials (RCTs). (2) Identify opportunities to improve the performance of Cochrane's centralized search and screening processes to identify references to eligible trials.
METHODS: We identified all references to RCTs (either published journal articles or trial registration records) with a publication or registration date between 1st January 2017 and 31st December 2018 that had been included in a Cochrane intervention review. We then viewed an audit trail for each included reference to determine if it had been identified by our centralized search process and subsequently added to CENTRAL.
RESULTS: We identified 650 references to included studies with a publication year of 2017 or 2018. Of those, 634 (97.5\%) had been captured by Cochrane's Centralised Search Service. Sixteen references had been missed by the Cochrane's Centralised Search Service: six had PubMed-not-MEDLINE status, four were missed by the centralized Embase search, three had been misclassified by Cochrane Crowd, one was from a journal not indexed in MEDLINE or Embase, one had only been added to Embase in 2019, and one reference had been rejected by the automated RCT machine learning classifier. Of the sixteen missed references, eight were the main or only publication to the trial in the review in which it had been included.
CONCLUSION: This analysis has shown that Cochrane's centralized search and screening processes are highly sensitive. It has also helped us to understand better why some references to eligible RCTs have been missed. The CSS is playing a critical role in helping to populate CENTRAL and is moving us toward making CENTRAL a comprehensive repository of RCTs.},
	language = {eng},
	journal = {Journal of Clinical Epidemiology},
	author = {Noel-Storr, A. H. and Dooley, G. and Wisniewski, S. and Glanville, J. and Thomas, J. and Cox, S. and Featherstone, R. and Foxlee, R.},
	month = aug,
	year = {2020},
	pmid = {32798713},
	keywords = {Cochrane central register of controlled trials, Crowdsourcing, Evidence synthesis, Information retrieval, Machine learning, Methodological filter, Randomized controlled trial, Systematic review}
}
